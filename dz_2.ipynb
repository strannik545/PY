{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a8de77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as T\n",
    "import pandas as pd\n",
    "import time\n",
    "pu = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8f54383",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRec:\n",
    "    \n",
    "    def __init__(self, num):\n",
    "        self.n = num\n",
    "        self.b = np.array(1)\n",
    "        \n",
    "        low = -0.01\n",
    "        high = 0.01\n",
    "        self.w = T.rand(n, dtype=T.float32, requires_grad=True).to(pu)\n",
    "        self.w = (high - low) * self.w + low\n",
    "        self.w.grad = T.zeros(n)\n",
    "        self.w.retain_grad()\n",
    "        \n",
    "        self.b = T.zeros(1, dtype=T.float32, requires_grad=True).to(pu)\n",
    "        self.b.grad = T.zeros(1)\n",
    "        self.b.retain_grad()\n",
    "    \n",
    "    def forward(x_t, w, b):\n",
    "        z = T.dot(x_t, w).reshape(1)\n",
    "        z += b\n",
    "        r = 1 / (1 + T.exp(-z))\n",
    "        return p\n",
    "    \n",
    "    def train(self, train_x, train_y, num, lrn_rate, epochs, reg = 0, verbose = 0):\n",
    "        indexes = np.arange(num)\n",
    "        \n",
    "        for epoch in range(0, epochs):\n",
    "            tot_loss = T.zeros(1, dtype=T.float32, requires_grad=True).to(pu)\n",
    "            tot_loss.grad = T.zeros(1)\n",
    "            tot_loss.retain_grad()\n",
    "\n",
    "            np.random.shuffle(indexes)\n",
    "            for ii in range(len(indexes)):\n",
    "                i = indexes[ii]\n",
    "                x_t = train_x[i]\n",
    "                target = train_y[i]\n",
    "                out = self.forward(x_t,self.w,self.b)\n",
    "                loss = (out - target).pow(2).sum()  # l2\n",
    "                tot_loss = loss + tot_loss\n",
    "\n",
    "            if reg == 1:\n",
    "                tot_loss = tot_loss + T.norm(self.w, p=1)\n",
    "            elif reg == 2:\n",
    "                tot_loss = tot_loss + T.norm(self.w, p=2)\n",
    "\n",
    "            tot_loss.backward(retain_graph=True)  # compute gradients\n",
    "\n",
    "            self.w.data += -1 * lrn_rate * self.w.grad.data\n",
    "            self.b.data += -1 * lrn_rate * self.b.grad.data\n",
    "\n",
    "            self.w.grad = T.zeros(n)\n",
    "            self.b.grad = T.zeros(1)\n",
    "\n",
    "            if epoch % verbose == 0:\n",
    "                print(\"epoch = %4d \" % epoch, end=\"\")\n",
    "                print(\"   loss = %6.4f\" % (tot_loss / num))\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return T.matmul(x, self.w) + self.b\n",
    "\n",
    "    def res(self, name=''):\n",
    "        print(\"Coef:\", name)\n",
    "        print(self.w.detach().numpy(), self.b.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52624601",
   "metadata": {},
   "outputs": [],
   "source": [
    "T.manual_seed(149462)\n",
    "np.random.seed(9849563)\n",
    "\n",
    "num = 100\n",
    "n = 5\n",
    "sigma = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17224a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91239822",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Shanghai_HMT_2010.csv')\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1a146db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['day', 'hour', 'PM_Jingan', 'PM_US Post' , 'PM_Xuhui', 'Iws', 'precipitation', 'Iprec', 'No', 'year', 'cbwd']:\n",
    "    data = data.drop(i, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f0c6379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>season</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>HUMI</th>\n",
       "      <th>PRES</th>\n",
       "      <th>TEMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26304</th>\n",
       "      <td>-1.557791</td>\n",
       "      <td>1.347979</td>\n",
       "      <td>-1.704071</td>\n",
       "      <td>0.018112</td>\n",
       "      <td>0.774887</td>\n",
       "      <td>-1.961308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26305</th>\n",
       "      <td>-1.557791</td>\n",
       "      <td>1.347979</td>\n",
       "      <td>-1.704071</td>\n",
       "      <td>0.018112</td>\n",
       "      <td>0.774887</td>\n",
       "      <td>-1.961308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26307</th>\n",
       "      <td>-1.557791</td>\n",
       "      <td>1.347979</td>\n",
       "      <td>-1.598843</td>\n",
       "      <td>0.317001</td>\n",
       "      <td>0.774887</td>\n",
       "      <td>-1.961308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26308</th>\n",
       "      <td>-1.557791</td>\n",
       "      <td>1.347979</td>\n",
       "      <td>-1.598843</td>\n",
       "      <td>0.628044</td>\n",
       "      <td>0.774887</td>\n",
       "      <td>-2.072632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26309</th>\n",
       "      <td>-1.557791</td>\n",
       "      <td>1.347979</td>\n",
       "      <td>-1.598843</td>\n",
       "      <td>0.628044</td>\n",
       "      <td>0.774887</td>\n",
       "      <td>-2.072632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52578</th>\n",
       "      <td>1.607977</td>\n",
       "      <td>1.347979</td>\n",
       "      <td>-1.388386</td>\n",
       "      <td>-0.450938</td>\n",
       "      <td>2.114730</td>\n",
       "      <td>-1.404688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52579</th>\n",
       "      <td>1.607977</td>\n",
       "      <td>1.347979</td>\n",
       "      <td>-1.283157</td>\n",
       "      <td>-0.195695</td>\n",
       "      <td>2.114730</td>\n",
       "      <td>-1.404688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52580</th>\n",
       "      <td>1.607977</td>\n",
       "      <td>1.347979</td>\n",
       "      <td>-1.072701</td>\n",
       "      <td>0.088277</td>\n",
       "      <td>2.114730</td>\n",
       "      <td>-1.293365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52581</th>\n",
       "      <td>1.607977</td>\n",
       "      <td>1.347979</td>\n",
       "      <td>-1.072701</td>\n",
       "      <td>0.088277</td>\n",
       "      <td>2.226384</td>\n",
       "      <td>-1.293365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52582</th>\n",
       "      <td>1.607977</td>\n",
       "      <td>1.347979</td>\n",
       "      <td>-1.177929</td>\n",
       "      <td>0.076675</td>\n",
       "      <td>2.114730</td>\n",
       "      <td>-1.404688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21436 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          month    season      DEWP      HUMI      PRES      TEMP\n",
       "26304 -1.557791  1.347979 -1.704071  0.018112  0.774887 -1.961308\n",
       "26305 -1.557791  1.347979 -1.704071  0.018112  0.774887 -1.961308\n",
       "26307 -1.557791  1.347979 -1.598843  0.317001  0.774887 -1.961308\n",
       "26308 -1.557791  1.347979 -1.598843  0.628044  0.774887 -2.072632\n",
       "26309 -1.557791  1.347979 -1.598843  0.628044  0.774887 -2.072632\n",
       "...         ...       ...       ...       ...       ...       ...\n",
       "52578  1.607977  1.347979 -1.388386 -0.450938  2.114730 -1.404688\n",
       "52579  1.607977  1.347979 -1.283157 -0.195695  2.114730 -1.404688\n",
       "52580  1.607977  1.347979 -1.072701  0.088277  2.114730 -1.293365\n",
       "52581  1.607977  1.347979 -1.072701  0.088277  2.226384 -1.293365\n",
       "52582  1.607977  1.347979 -1.177929  0.076675  2.114730 -1.404688\n",
       "\n",
       "[21436 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data -= data.mean()\n",
    "data /= data.std()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6a86685",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['PRES'] = data['PRES'].apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "660359bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = T.tensor(data.drop(['PRES'], axis=1).to_numpy(), dtype=T.float32).to(pu)\n",
    "train_y = T.tensor(data['PRES'].to_numpy(), dtype=T.long).to(pu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c388754",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-92c2302df55a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogRec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0005\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'without reg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-56b19e1cff71>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_x, train_y, num, lrn_rate, epochs, reg, verbose)\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0mx_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# l2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[0mtot_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtot_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "num = int(train_y.size()[0])\n",
    "n = 5\n",
    "res = LogRec(n)\n",
    "res.train(train_x, train_y, num, 0.0005, 100, reg=0, verbose=10)\n",
    "res.res('without reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41900b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaef1e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "res3 = LogisticRegression()\n",
    "res3.fit(data.drop(['PRES'], axis=1).to_numpy(), data['PRES'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a582430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.65479326  0.75872407 -0.62277762 -1.12085302 -4.15814051]]\n"
     ]
    }
   ],
   "source": [
    "print(res3.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f004e07a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
